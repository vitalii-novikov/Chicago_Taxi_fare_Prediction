scale_params <- preProcess(train[, -which(names(train) == "fare")], method = c("center", "scale"))
train <- predict(scale_params, train)
test <- predict(scale_params, test)
# Extract target and clean test set
y <- test$fare
for (m in names(models)) {
print(sprintf("▶️  Working on %s with  …", m ))
tryCatch({
if (m == "RF") {
# ----- Random-Forest --------------------------------------------------
model_obj <- randomForest(form, data = train, na.action = na.omit)
pred <- predict(model_obj, newdata = test, type = "response")
} else if (m == "NEURALNET") {
# ----- Neural-net -----------------------------------------------------
# neuralnet needs purely numeric matrix input
nn_train <- model.matrix(form, data = train)[, -1]  # drop intercept
nn_test  <- model.matrix(form, data = test)[, -1]
nn_df <- cbind(fare = train$fare, as.data.frame(nn_train))
nn_formula <- as.formula(paste("fare ~",
paste(colnames(nn_train), collapse = " + ")))
model_obj <- neuralnet("fare ~ .", data = nn_df, hidden = c(2),
linear.output = TRUE, stepmax = 1e6)
pred_raw <- compute(model_obj, nn_test)$net.result
pred <- as.numeric(pred_raw)
} else {
}
# ----- common evaluation ----------------------------------------------
print(evaluate_and_plot_full_model(
y               = y,
duration_seconds = test$trip_seconds,
prediction      = pred,
model           = m,
dataset         = "../all_data/datasets/dsSmall.csv"
))
}, error = function(e) {
message(sprintf("❌ Error with model %s on dataset ", m,)
})
}
ensureLibrary <- function(pkg) {
suppressPackageStartupMessages({
if (!requireNamespace(pkg, quietly = TRUE)) {
install.packages(pkg)
}
library(pkg, character.only = TRUE)
})
}
ensureLibrary("httr")
ensureLibrary("jsonlite")
ensureLibrary("dplyr")
ensureLibrary("tidyr")
ensureLibrary("lubridate")
ensureLibrary("ggplot2")
ensureLibrary("readr")
ensureLibrary("caret")
ensureLibrary("purrr")
ensureLibrary("ggplot2")
ensureLibrary("neuralnet")
ensureLibrary("xgboost")
ensureLibrary("randomForest")
ensureLibrary("patchwork")
ensureLibrary("Metrics")
load_all_csv <- function(folder_path) {
files <- list.files(path = folder_path, pattern = "\\.csv$", full.names = TRUE)
if (length(files) == 0) {
warning("No CSV files found in the folder.")
return(NULL)
}
all_data <- list()
for (f in files) {
temp <- read.csv(f)
temp <- temp%>% select(-X, -trip_start_timestamp, -pickup_census_tract, -dropoff_census_tract, -pickup_census_tract_centroid, -dropoff_census_tract_centroid, -type, -dropoff_census_tract.1, -pickup_census_tract.1) %>% mutate(weekday = as.factor(weekday))
all_data[[f]] <- temp  # use filename as list name (optional but useful)
}
return(all_data)
}
evaluate_and_plot_full_model <- function(y, duration_seconds, prediction, model = "Model", dataset = "Dataset") {
if (length(y) != length(prediction) || length(y) != length(duration_seconds)) {
stop("All input vectors must have the same length.")
}
# Convert inputs
y <- as.numeric(y)
prediction <- as.numeric(prediction)
duration_minutes <- duration_seconds / 60
# --- Metrics ---
valid_idx <- which(!is.na(y) & !is.na(prediction) & !is.na(duration_minutes) & y != 0)
y_valid <- y[valid_idx]
prediction_valid <- prediction[valid_idx]
duration_valid <- duration_minutes[valid_idx]
rmse_val <- tryCatch(rmse(y_valid, prediction_valid), error = function(e) NA)
mae_val <- tryCatch(mae(y_valid, prediction_valid), error = function(e) NA)
r2_val <- tryCatch(1 - sum((y_valid - prediction_valid)^2) / sum((y_valid - mean(y_valid))^2), error = function(e) NA)
duration_n_10min <- max(duration_valid %/% 10, 1) # how many 10-minute intervals in each trip
rmse_10min <- round(sqrt(mean( (
(y_valid - prediction_valid)/duration_n_10min
)^2 , na.rm = TRUE)),2)
ae_percent <- (abs(y_valid - prediction_valid) / y_valid) * 100 - 1
mean_ae_percent <- round(mean(ae_percent, na.rm = TRUE),2)
is_ok <- (rmse_10min < 2) & (mean_ae_percent < 0.05)
# --- Plots ---
# 1. Prediction vs Actual
p_pred <- ggplot(data.frame(y = y_valid, prediction = prediction_valid), aes(x = y, y = prediction)) +
geom_point(color = "steelblue", alpha = 0.6) +
geom_abline(intercept = 0, slope = 1, color = "red", linetype = "dashed") +
labs(
title = paste(model, "Predictions"),
subtitle = paste0("(N = ", length(y_valid), ")"),
x = "Actual",
y = "Predicted"
) +
theme_minimal()
# 2. Metric bar chart
metric_df <- data.frame(
Metric = c("RMSE", "MAE", "R²"),
Value = c(rmse_val, mae_val, r2_val)
)
p_metrics <- ggplot(metric_df, aes(x = Metric, y = Value, fill = Metric)) +
geom_col(width = 0.6, show.legend = FALSE) +
geom_text(aes(label = round(Value, 2)), vjust = -0.5, size = 4) +
scale_y_continuous(expand = expansion(mult = c(0, 0.4))) +
labs(
title = "Model Evaluation Metrics",
y = NULL, x = NULL
) +
theme_minimal()
# 3. Summary: RMSE 10min vs %AE
summary_df <- data.frame(
RMSE_10min = rmse_10min,
Mean_AE_percent = mean_ae_percent,
Status = ifelse(is_ok, "OK", "Not OK")
)
p_summary <- ggplot(summary_df, aes(x = RMSE_10min, y = Mean_AE_percent)) +
geom_point(aes(color = Status), size = 5) +
geom_vline(xintercept = 2, linetype = "dashed", color = "black") +
geom_hline(yintercept = 0.05, linetype = "dashed", color = "black") +
scale_color_manual(values = c("OK" = "green", "Not OK" = "red")) +
labs(
title = "Evaluation: Scaled RMSE vs % Error",
x = "RMSE (scaled to 10 min)",
y = "Mean Absolute Error (%)"
) +
theme_minimal()
# 4. Individual error scatter
individual_df <- data.frame(
AbsoluteError_10min = abs(y_valid - prediction_valid) * (10 / duration_valid),
PercentError = ae_percent
)
thresholds_df <- data.frame(
Metric = c("RMSE_10min", "Mean AE %"),
Value = c(rmse_10min, mean_ae_percent),
Threshold = c(2, 0.05)
)
p_thresholds <- ggplot(thresholds_df, aes(x = Metric, y = Value, fill = Metric)) +
geom_col(width = 0.5, show.legend = FALSE) +
geom_hline(aes(yintercept = Threshold), linetype = "dashed", color = "red") +
geom_text(aes(label = round(Value, 2)), vjust = -0.5, size = 4) +
scale_y_continuous(expand = expansion(mult = c(0, 0.2))) +
labs(
title = "Scaled Error Metrics vs Thresholds",
y = "Value", x = NULL
) +
theme_minimal()
p_individual <- ggplot(individual_df, aes(x = AbsoluteError_10min, y = duration_valid)) +
geom_point(alpha = 0.6, color = "blue") +
geom_hline(yintercept = 0.05, linetype = "dashed", color = "black") +
labs(
title = "Individual Errors",
x = "Absolute Error (scaled to 10 min)",
y = "duration in minutes"
) +
theme_minimal()
# RMSE_10min Bar Plot
p_rmse10 <- ggplot(data.frame(Value = rmse_10min), aes(x = "RMSE (10min)", y = Value)) +
geom_col(fill = ifelse(rmse_10min <= 2, "green", "red"), width = 0.5) +
geom_hline(yintercept = 2, linetype = "dashed", color = "black") +
geom_text(aes(label = round(Value, 2)), vjust = -0.5, size = 4) +
scale_y_continuous(expand = expansion(mult = c(0, 0.2))) +
labs(
title = "RMSE scaled to 10 minutes",
x = NULL,
y = NULL
) +
theme_minimal() +
ylim(c(0,5))
# Mean AE % Bar Plot
p_ae_percent <- ggplot(data.frame(Value = mean_ae_percent), aes(x = "Mean AE %", y = Value)) +
geom_col(fill = ifelse(mean_ae_percent <= 5, "green", "red"), width = 0.5) +
geom_hline(yintercept = 5, linetype = "dashed", color = "black") +
geom_text(aes(label = round(Value, 3)), vjust = -0.5, size = 4) +
scale_y_continuous(expand = expansion(mult = c(0, 0.2))) +
labs(
title = "Mean Absolute Error %",
x = NULL,
y = NULL
) +
theme_minimal() +
ylim(c(0,100))
# --- Combine plots ---
combined_plot <- (p_pred | p_metrics) / ((p_rmse10 | p_ae_percent) | p_individual)
return(combined_plot)
}
remove_outliers_z <- function(df, feature1, feature2, threshold = 3) {
z1 <- abs(scale(df[[feature1]]))
z2 <- abs(scale(df[[feature2]]))
df_clean <- df[(z1 < threshold) & (z2 < threshold), ]
return(df_clean)
}
df <- load_all_csv("../all_data/datasets")
form <- fare ~ .
percentage <- 0.8
models <- list(             # handled in its own block      # random-forest
"RF" = NULL        # feed-forward neural net
)
# -----------------------------------------------------------------------------
dataSet <- df[["../all_data/datasets/dsSmall.csv"]] %>% filter(trip_seconds > 60)
dataSet <- na.omit(dataSet)
dataSet$weekday <- as.numeric(factor(dataSet$weekday))
dataSet$fareSeconds <- dataSet$fare/dataSet$trip_seconds
dataSet <- remove_outliers_z(dataSet, "fare", "fareSeconds", 1.5)
dataSet <- remove_outliers_z(dataSet, "trip_miles", "trip_seconds", 1.5)
dataSet <- dataSet %>% select(-fareSeconds)
train_index <- sample(1:nrow(dataSet), 0.3 * nrow(dataSet))
train <- dataSet[train_index, ]
test <- dataSet[-train_index, ]
scale_params <- preProcess(train[, -which(names(train) == "fare")], method = c("center", "scale"))
train <- predict(scale_params, train)
test <- predict(scale_params, test)
# Extract target and clean test set
y <- test$fare
for (m in names(models)) {
print(sprintf("▶️  Working on %s with  …", m ))
tryCatch({
if (m == "RF") {
# ----- Random-Forest --------------------------------------------------
model_obj <- randomForest(form, data = train, na.action = na.omit)
pred <- predict(model_obj, newdata = test, type = "response")
} else if (m == "NEURALNET") {
# ----- Neural-net -----------------------------------------------------
# neuralnet needs purely numeric matrix input
nn_train <- model.matrix(form, data = train)[, -1]  # drop intercept
nn_test  <- model.matrix(form, data = test)[, -1]
nn_df <- cbind(fare = train$fare, as.data.frame(nn_train))
nn_formula <- as.formula(paste("fare ~",
paste(colnames(nn_train), collapse = " + ")))
model_obj <- neuralnet("fare ~ .", data = nn_df, hidden = c(2),
linear.output = TRUE, stepmax = 1e6)
pred_raw <- compute(model_obj, nn_test)$net.result
pred <- as.numeric(pred_raw)
} else {
}
# ----- common evaluation ----------------------------------------------
print(evaluate_and_plot_full_model(
y               = y,
duration_seconds = test$trip_seconds,
prediction      = pred,
model           = m,
dataset         = "../all_data/datasets/dsSmall.csv"
))
}, error = function(e) {
message(sprintf("❌ Error with model %s on dataset ", m,)
})
}
models <- list(             # handled in its own block      # random-forest
"RF" = NULL        # feed-forward neural net
)
# -----------------------------------------------------------------------------
dataSet <- df[["../all_data/datasets/dsSmall.csv"]] %>% filter(trip_seconds > 60)
dataSet <- na.omit(dataSet)
dataSet$weekday <- as.numeric(factor(dataSet$weekday))
dataSet$fareSeconds <- dataSet$fare/dataSet$trip_seconds
dataSet <- remove_outliers_z(dataSet, "fare", "fareSeconds", 1.5)
dataSet <- remove_outliers_z(dataSet, "trip_miles", "trip_seconds", 1.5)
dataSet <- dataSet %>% select(-fareSeconds)
train_index <- sample(1:nrow(dataSet), 0.3 * nrow(dataSet))
train <- dataSet[train_index, ]
test <- dataSet[-train_index, ]
scale_params <- preProcess(train[, -which(names(train) == "fare")], method = c("center", "scale"))
train <- predict(scale_params, train)
test <- predict(scale_params, test)
# Extract target and clean test set
y <- test$fare
for (m in names(models)) {
print(sprintf("▶️  Working on %s with  …", m ))
tryCatch({
if (m == "RF") {
# ----- Random-Forest --------------------------------------------------
model_obj <- randomForest(form, data = train, na.action = na.omit)
pred <- predict(model_obj, newdata = test, type = "response")
} else if (m == "NEURALNET") {
# ----- Neural-net -----------------------------------------------------
# neuralnet needs purely numeric matrix input
nn_train <- model.matrix(form, data = train)[, -1]  # drop intercept
nn_test  <- model.matrix(form, data = test)[, -1]
nn_df <- cbind(fare = train$fare, as.data.frame(nn_train))
nn_formula <- as.formula(paste("fare ~",
paste(colnames(nn_train), collapse = " + ")))
model_obj <- neuralnet("fare ~ .", data = nn_df, hidden = c(2),
linear.output = TRUE, stepmax = 1e6)
pred_raw <- compute(model_obj, nn_test)$net.result
pred <- as.numeric(pred_raw)
} else {
}
# ----- common evaluation ----------------------------------------------
print(evaluate_and_plot_full_model(
y               = y,
duration_seconds = test$trip_seconds,
prediction      = pred,
model           = m,
dataset         = "../all_data/datasets/dsSmall.csv"
))
}, error = function(e) {
message(sprintf("❌ Error with model %s on dataset ", m)
})
}
models <- list(             # handled in its own block      # random-forest
"RF" = NULL        # feed-forward neural net
)
# -----------------------------------------------------------------------------
dataSet <- df[["../all_data/datasets/dsSmall.csv"]] %>% filter(trip_seconds > 60)
dataSet <- na.omit(dataSet)
dataSet$weekday <- as.numeric(factor(dataSet$weekday))
dataSet$fareSeconds <- dataSet$fare/dataSet$trip_seconds
dataSet <- remove_outliers_z(dataSet, "fare", "fareSeconds", 1.5)
dataSet <- remove_outliers_z(dataSet, "trip_miles", "trip_seconds", 1.5)
dataSet <- dataSet %>% select(-fareSeconds)
train_index <- sample(1:nrow(dataSet), 0.3 * nrow(dataSet))
train <- dataSet[train_index, ]
test <- dataSet[-train_index, ]
scale_params <- preProcess(train[, -which(names(train) == "fare")], method = c("center", "scale"))
train <- predict(scale_params, train)
test <- predict(scale_params, test)
# Extract target and clean test set
y <- test$fare
for (m in names(models)) {
print(sprintf("▶️  Working on %s with  …", m ))
tryCatch({
if (m == "RF") {
# ----- Random-Forest --------------------------------------------------
model_obj <- randomForest(as.formula("fare ~ ."), data = train, na.action = na.omit)
pred <- predict(model_obj, newdata = test, type = "response")
} else if (m == "NEURALNET") {
# ----- Neural-net -----------------------------------------------------
# neuralnet needs purely numeric matrix input
nn_train <- model.matrix(form, data = train)[, -1]  # drop intercept
nn_test  <- model.matrix(form, data = test)[, -1]
nn_df <- cbind(fare = train$fare, as.data.frame(nn_train))
nn_formula <- as.formula(paste("fare ~",
paste(colnames(nn_train), collapse = " + ")))
model_obj <- neuralnet("fare ~ .", data = nn_df, hidden = c(2),
linear.output = TRUE, stepmax = 1e6)
pred_raw <- compute(model_obj, nn_test)$net.result
pred <- as.numeric(pred_raw)
} else {
}
# ----- common evaluation ----------------------------------------------
print(evaluate_and_plot_full_model(
y               = y,
duration_seconds = test$trip_seconds,
prediction      = pred,
model           = m,
dataset         = "../all_data/datasets/dsSmall.csv"
))
}, error = function(e) {
message(sprintf("❌ Error with model %s on dataset: %s", m, e$message))
})
}
runApp()
models <- list(
"XGBOOST" = xgboost,
"GLM" = glm,
"LM" = lm
)
counter = 0
for (ds in rev(names(df))) {
dataSet <- df[[ds]] %>% filter(trip_seconds > 60)
dataSet$weekday <- as.numeric(factor(dataSet$weekday))
dataSet$fareSeconds <- dataSet$fare/dataSet$trip_seconds
dataSet <- remove_outliers_z(dataSet, "fare", "fareSeconds", 1.5)
dataSet <- remove_outliers_z(dataSet, "trip_miles", "trip_seconds", 1.5)
dataSet <- dataSet %>% select(-fareSeconds)
train_index <- sample(1:nrow(dataSet), percentage * nrow(dataSet))
train <- dataSet[train_index, ] %>% drop_na()
test <- dataSet[-train_index, ] %>% drop_na()
test_durations <- test$trip_seconds
scale_params <- preProcess(train[, -which(names(train) == "fare")], method = c("center", "scale"))
train_scaled <- predict(scale_params, train)
test_scaled <- predict(scale_params, test)
train_scaled$fare <- train$fare
test_scaled$fare <- test$fare
train <- train_scaled
test <- test_scaled
# Extract target and clean test set
y <- test$fare
for (m in names(models)) {
print(paste0("Working on ", m , " with ", ds))
model_obj <- NULL
pred <- NULL
tryCatch({
if (m == "XGBOOST") {
train_clean <- train
test_clean <- test
xform <- fare ~ . - 1  # consistent formula without intercept
train_matrix <- model.matrix(xform, data = train_clean)
test_matrix <- model.matrix(xform, data = test_clean)
# Prepare labels and durations
train_labels <- train_clean$fare
test_labels <- test_clean$fare
# DMatrix conversion
dtrain <- xgb.DMatrix(data = train_matrix, label = train_labels)
dtest <- xgb.DMatrix(data = test_matrix)
# Train
params <- list(objective = "reg:squarederror", eta = 0.1, max_depth = 6)
model_obj <- xgboost(data = dtrain, params = params, nrounds = 100, verbose = 0)
# Predict
pred <- predict(model_obj, dtest)
# Evaluate
print(evaluate_and_plot_full_model(
y = test_labels,
duration_seconds = test_durations,
prediction = pred,
model = m,
dataset = ds
))
save_path <- paste0("fare_xgb_",counter,".model")
xgb.save(xgb_model, save_path)
counter <- counter +1
} else {
model_func <- models[[m]]
model_obj <- model_func(form, data = train, na.action = na.omit)
pred <- predict(model_obj, newdata = test %>% select(-fare))
print(evaluate_and_plot_full_model(y, test$trip_seconds, pred, model = m, dataset = ds))
}
# Plot evaluation
}, error = function(e) {
cat(paste0("❌ Error with model ", m, " on dataset ", ds, ": ", e$message, "\n"))
})
}
}
models <- list(
"XGBOOST" = xgboost,
"GLM" = glm,
"LM" = lm
)
counter = 0
for (ds in rev(names(df))) {
dataSet <- df[[ds]] %>% filter(trip_seconds > 60)
dataSet$weekday <- as.numeric(factor(dataSet$weekday))
dataSet$fareSeconds <- dataSet$fare/dataSet$trip_seconds
dataSet <- remove_outliers_z(dataSet, "fare", "fareSeconds", 1.5)
dataSet <- remove_outliers_z(dataSet, "trip_miles", "trip_seconds", 1.5)
dataSet <- dataSet %>% select(-fareSeconds)
train_index <- sample(1:nrow(dataSet), percentage * nrow(dataSet))
train <- dataSet[train_index, ] %>% drop_na()
test <- dataSet[-train_index, ] %>% drop_na()
test_durations <- test$trip_seconds
scale_params <- preProcess(train[, -which(names(train) == "fare")], method = c("center", "scale"))
train_scaled <- predict(scale_params, train)
test_scaled <- predict(scale_params, test)
train_scaled$fare <- train$fare
test_scaled$fare <- test$fare
train <- train_scaled
test <- test_scaled
# Extract target and clean test set
y <- test$fare
for (m in names(models)) {
print(paste0("Working on ", m , " with ", ds))
model_obj <- NULL
pred <- NULL
tryCatch({
if (m == "XGBOOST") {
train_clean <- train
test_clean <- test
xform <- fare ~ . - 1  # consistent formula without intercept
train_matrix <- model.matrix(xform, data = train_clean)
test_matrix <- model.matrix(xform, data = test_clean)
# Prepare labels and durations
train_labels <- train_clean$fare
test_labels <- test_clean$fare
# DMatrix conversion
dtrain <- xgb.DMatrix(data = train_matrix, label = train_labels)
dtest <- xgb.DMatrix(data = test_matrix)
# Train
params <- list(objective = "reg:squarederror", eta = 0.1, max_depth = 6)
model_obj <- xgboost(data = dtrain, params = params, nrounds = 100, verbose = 0)
# Predict
pred <- predict(model_obj, dtest)
# Evaluate
print(evaluate_and_plot_full_model(
y = test_labels,
duration_seconds = test_durations,
prediction = pred,
model = m,
dataset = ds
))
save_path <- paste0("fare_xgb_",counter,".model")
xgb.save(model_obj, save_path)
counter <- counter +1
} else {
model_func <- models[[m]]
model_obj <- model_func(form, data = train, na.action = na.omit)
pred <- predict(model_obj, newdata = test %>% select(-fare))
print(evaluate_and_plot_full_model(y, test$trip_seconds, pred, model = m, dataset = ds))
}
# Plot evaluation
}, error = function(e) {
cat(paste0("❌ Error with model ", m, " on dataset ", ds, ": ", e$message, "\n"))
})
}
}
runApp()
colnames(df[["../all_data/datasets/dsSmall.csv"]])
runApp()
runApp()
