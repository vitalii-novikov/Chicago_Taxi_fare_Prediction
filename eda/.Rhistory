) %>%
summarise(
trip_seconds = mean(as.numeric(trip_seconds), na.rm = TRUE),
trip_miles   = mean(as.numeric(trip_miles), na.rm = TRUE),
fare         = mean(as.numeric(fare), na.rm = TRUE),
tips         = mean(as.numeric(tips), na.rm = TRUE),
tolls        = mean(as.numeric(tolls), na.rm = TRUE),
extras       = mean(as.numeric(extras), na.rm = TRUE),
trip_total   = mean(as.numeric(trip_total), na.rm = TRUE),
.groups = "drop"
)
print("\n--------------------")
print(paste0("Data for month total: ", nrow(monthly_data)))
print(paste0("cleaned Data for month: ",nrow(cleaned_data)))
print(paste0("finald Data for month: ",nrow(final_data), " Reduction by ", round(nrow(final_data)/nrow(montly_data)*100,2), "%"))
print("--------------------\n")
file_name <- sprintf("../all_data/chicago_taxi_%04d_%02d.csv", year, month)
write_csv(final_data, file_name)
cat("  ✔ Saved:", file_name, "- Total rows:", nrow(final_data), "\n")
} else {
cat("  ⚠ No data for:", year, month, "\n")
}
}
}
# setup
years = c(2013)
base_url = "https://data.cityofchicago.org/resource/wrvz-psew.json"
limit = 49000
# setup
years = c(2013)
base_url = "https://data.cityofchicago.org/resource/wrvz-psew.json"
limit = 50000
for (year in years) {
for (month in c(1)) {  # You can replace c(1) with 1:12 for full-year
# Create time range for the full month
start_date <- sprintf("%04d-%02d-01T00:00:00", year, month)
if (month == 12) {
end_date <- sprintf("%04d-01-01T00:00:00", year + 1)
} else {
end_date <- sprintf("%04d-%02d-01T00:00:00", year, month + 1)
}
offset <- 0L
all_data <- list()
finished <- FALSE
cat("Downloading:", year, month, "\n")
while (!finished) {
resp <- GET(
url = base_url,
query = list(
`$where` = paste0(
"trip_start_timestamp >= '", start_date,
"' AND trip_start_timestamp < '", end_date, "'"
),
`$limit` = limit,
`$offset` = as.integer(offset)
)
)
if (status_code(resp) != 200) {
print(resp$url)
warning("API error at ", year, "-", month, " offset ", offset)
break
}
data_chunk <- fromJSON(rawToChar(resp$content))
if (length(data_chunk) == 0) {
finished <- TRUE
break
}
clean_data <- clean_chunk(data_chunk)
all_data[[length(all_data) + 1]] <- clean_data
cat(sprintf("  Rows downloaded: %d\n", offset + nrow(clean_data)))
offset <- offset + limit
}
if (length(all_data) > 0) {
monthly_data <- bind_rows(all_data)
# Clean timestamps
cleaned_data <- monthly_data %>%
filter(!is.na(trip_start_timestamp), !is.na(trip_end_timestamp)) %>%
mutate(
trip_start_timestamp = suppressWarnings(ymd_hms(trip_start_timestamp)),
trip_end_timestamp   = suppressWarnings(ymd_hms(trip_end_timestamp))
) %>%
filter(!is.na(trip_start_timestamp), !is.na(trip_end_timestamp)) %>%
mutate(
trip_start_timestamp = floor_date(trip_start_timestamp, unit = "15 minutes"),
trip_end_timestamp   = floor_date(trip_end_timestamp, unit = "15 minutes")
)
# Select and aggregate
final_data <- cleaned_data %>%
select(
trip_start_timestamp,
trip_end_timestamp,
pickup_census_tract,
dropoff_census_tract,
trip_seconds,
trip_miles,
fare,
tips,
tolls,
extras,
trip_total
) %>%
group_by(
trip_start_timestamp,
trip_end_timestamp,
pickup_census_tract,
dropoff_census_tract
) %>%
summarise(
trip_seconds = mean(as.numeric(trip_seconds), na.rm = TRUE),
trip_miles   = mean(as.numeric(trip_miles), na.rm = TRUE),
fare         = mean(as.numeric(fare), na.rm = TRUE),
tips         = mean(as.numeric(tips), na.rm = TRUE),
tolls        = mean(as.numeric(tolls), na.rm = TRUE),
extras       = mean(as.numeric(extras), na.rm = TRUE),
trip_total   = mean(as.numeric(trip_total), na.rm = TRUE),
.groups = "drop"
)
print("\n--------------------")
print(paste0("Data for month total: ", nrow(monthly_data)))
print(paste0("cleaned Data for month: ",nrow(cleaned_data)))
print(paste0("finald Data for month: ",nrow(final_data), " Reduction by ", round(nrow(final_data)/nrow(monthly_data)*100,2), "%"))
print("--------------------\n")
file_name <- sprintf("../all_data/chicago_taxi_%04d_%02d.csv", year, month)
write_csv(final_data, file_name)
cat("  ✔ Saved:", file_name, "- Total rows:", nrow(final_data), "\n")
} else {
cat("  ⚠ No data for:", year, month, "\n")
}
}
}
shiny::runApp()
runApp()
library(tidyverse)
shiny::runApp()
leaflet(sf_df) %>%
addTiles() %>%
addPolygons(color = "blue", weight = 2, fillOpacity = 0.5, popup = ~NAME10)
install.packages(c("sf", "leaflet", "readr", "dplyr"))
library(sf)
library(leaflet)
library(readr)
library(dplyr)
# Adjust the path to your CSV file
df <- read_csv("CensusTracts.csv", sep=";")
# Adjust the path to your CSV file
df <- read_csv("CensusTracts.csv", sep=";")
# Adjust the path to your CSV file
df <- read_csv("CensusTracts.csv", delim =";")
# Adjust the path to your CSV file
df <- read_delim("CensusTracts.csv", delim = ";")
setwd("D:\Chicago_Taxi_fare_Prediction\eda")
setwd("D:\\Chicago_Taxi_fare_Prediction\\eda")
# Adjust the path to your CSV file
df <- read_delim("CensusTracts.csv", delim = ";")
# Convert the WKT string column to sf geometry
sf_df <- df %>%
mutate(geometry = st_as_sfc(the_geom, crs = 4326)) %>%
st_as_sf()
leaflet(sf_df) %>%
addTiles() %>%
addPolygons(color = "blue", weight = 2, fillOpacity = 0.5, popup = ~NAME10)
centroids <- read_csv("../all_data/chicago_taxi_2024_01.csv")
centroids <- centroids %>% select(pickup_centroid_latitude, pickup_centroid_longitude, dropoff_centroid_latitude, dropoff_centroid_longitude)
View(centroids)
centroids <- centroids %>%
select(pickup_centroid_latitude, pickup_centroid_longitude,
dropoff_centroid_latitude, dropoff_centroid_longitude) %>%
pivot_longer(cols = everything(),
names_to = c("type", ".value"),
names_pattern = "(pickup|dropoff)_centroid_(latitude|longitude)") %>%
distinct(latitude, longitude)
library(dplyr)
library(tidyr)
centroids <- centroids %>%
select(pickup_centroid_latitude, pickup_centroid_longitude,
dropoff_centroid_latitude, dropoff_centroid_longitude) %>%
pivot_longer(cols = everything(),
names_to = c("type", ".value"),
names_pattern = "(pickup|dropoff)_centroid_(latitude|longitude)") %>%
distinct(latitude, longitude)
sf_df <- read_delim("CensusTracts.csv", delim = ";") %>%
mutate(geometry = st_as_sfc(the_geom, crs = 4326)) %>%
st_as_sf()
# Read coordinate points
coords_df <- read_csv("../all_data/chicago_taxi_2024_01.csv")  # Replace with actual file path
# Combine pickup and dropoff coordinates, filter unique
points_df <- coords_df %>%
select(pickup_centroid_latitude, pickup_centroid_longitude,
dropoff_centroid_latitude, dropoff_centroid_longitude) %>%
pivot_longer(cols = everything(),
names_to = c("type", ".value"),
names_pattern = "(pickup|dropoff)_centroid_(latitude|longitude)") %>%
distinct(latitude, longitude)
# Convert to sf object (points)
points_sf <- st_as_sf(points_df, coords = c("longitude", "latitude"), crs = 4326)
# Combine pickup and dropoff coordinates, filter unique
points_df <- coords_df %>%
select(pickup_centroid_latitude, pickup_centroid_longitude,
dropoff_centroid_latitude, dropoff_centroid_longitude) %>%
pivot_longer(cols = everything(),
names_to = c("type", ".value"),
names_pattern = "(pickup|dropoff)_centroid_(latitude|longitude)") %>%
distinct(latitude, longitude) %>% filter(!is.na(latitude) & !is.na(longitude))
# Convert to sf object (points)
points_sf <- st_as_sf(points_df, coords = c("longitude", "latitude"), crs = 4326)
# Plot polygons and points
leaflet() %>%
addTiles() %>%
addPolygons(data = sf_df, color = "blue", weight = 2, fillOpacity = 0.3, popup = ~NAME10) %>%
addCircleMarkers(data = points_sf, radius = 4, color = "red", stroke = FALSE, fillOpacity = 0.8)
ensureLibrary <- function(pkg) {
suppressPackageStartupMessages({
if (!requireNamespace(pkg, quietly = TRUE)) {
install.packages(pkg)
}
library(pkg, character.only = TRUE)
})
}
ensureLibrary("httr")
ensureLibrary("jsonlite")
ensureLibrary("dplyr")
ensureLibrary("tidyr")
ensureLibrary("lubridate")
ensureLibrary("ggplot2")
ensureLibrary("readr")
ensureLibrary("caret")
ensureLibrary("purrr")
ensureLibrary("ggplot2")
ensureLibrary("sf")
ensureLibrary("igraph")
ensureLibrary("ggraph")
load_all_csv <- function(folder_path) {
files <- list.files(path = folder_path, pattern = "\\.csv$", full.names = TRUE)
files <- files[!grepl("census|tract", files, ignore.case = TRUE)]
if (length(files) == 0) {
warning("No CSV files found in the folder.")
return(NULL)
}
all_data <- lapply(files, function(file) {
temp <- read_csv(file, show_col_types = FALSE)
problems(temp)
print(paste("Rows before filtering:", nrow(temp)))
return(temp)
}) %>%
bind_rows()
return(all_data)
}
df <- load_all_csv("../all_data/")
summary(df)
print(paste("Number of rows in original data:", nrow(df)))
df_clean <- df %>%
filter(
!is.na(pickup_census_tract),
!is.na(dropoff_census_tract),
!is.na(pickup_community_area),
!is.na(dropoff_community_area),
!is.na(trip_seconds),
!is.na(trip_miles),
!is.na(fare),
!is.na(trip_total)
)
print(paste("Number of rows after filtering:", nrow(df_clean)))
summary(df_clean)
ggplot(df_clean, aes(x = trip_seconds / 60)) +
geom_histogram(fill = "steelblue") +
labs(x = "Trip Duration (minutes)", y = "Count") +
coord_cartesian(xlim = c(0, 120)) +
theme_minimal()
ggplot(df_clean, aes(x = trip_miles)) +
geom_histogram(bins=5,fill = "steelblue") +
labs(x = "Trip Miles", y = "Count") +
theme_minimal()
df_clean <- df_clean %>%
mutate(speed_mph = trip_miles / (trip_seconds / 3600))
summary(df_clean$speed_mph)
unrealistic_speeds <- df_clean %>% filter(speed_mph > 80)
nrow(unrealistic_speeds)
ggplot(df_clean, aes(x = speed_mph)) +
geom_histogram(bins = 100, fill = "skyblue", alpha = 0.7) +
xlim(0, 100) +  # Focus on realistic range, ignoring extreme outliers
labs(title = "Distribution of Taxi Speeds (mph)",
x = "Speed (mph)",
y = "Number of Trips") +
theme_minimal()
df_clean <- df_clean %>% filter(speed_mph > 1, speed_mph <= 80)
ggplot(df_clean, aes(x = trip_miles, y = trip_seconds / 60)) +
geom_point(alpha = 0.3) +
labs(x = "Trip Miles", y = "Trip Duration (minutes)") +
#coord_cartesian(xlim = c(0, 200)) +
theme_minimal()
library(leaflet)
ggplot(df_clean, aes(x = payment_type, y = tips)) +
geom_boxplot(fill = "orange") +
labs(x = "Payment Type", y = "Tips (USD)") +
theme_minimal()
df_clean$hour <- hour(df_clean$trip_end_timestamp)
ggplot(df_clean, aes(x = hour)) +
geom_bar(fill = "blue") +
labs(x = "Hour of Day", y = "Number of Trips") +
theme_minimal()
df_clean %>%
group_by(company) %>%
summarise(total_revenue = sum(trip_total, na.rm = TRUE)) %>%
arrange(desc(total_revenue)) %>%
top_n(10) %>%
ggplot(aes(x = reorder(company, total_revenue), y = total_revenue)) +
geom_col(fill = "darkgreen") +
coord_flip() +
labs(x = "Company", y = "Total Revenue (USD)") +
theme_minimal()
leaflet(df_clean[1:1000,]) %>%
addTiles() %>%
addCircleMarkers(
~pickup_centroid_longitude, ~pickup_centroid_latitude,
radius = 2,
color = "blue",
opacity = 0.5
)
avg_fare <- df_clean %>%
group_by(pickup_community_area) %>%
summarise(avg_fare = mean(fare, na.rm = TRUE))
community_shapes <- read_delim("../all_data/CensusTracts.csv",delim=';')
rides_origin_count <- df_clean %>%
group_by(pickup_community_area) %>%
summarise(origin_count = n()) %>%
arrange(desc(origin_count))
rides_dest_count <- df_clean %>%
group_by(dropoff_community_area) %>%
summarise(dest_count = n()) %>%
arrange(desc(dest_count))
popular_pairs <- df_clean %>%
group_by(pickup_community_area, dropoff_community_area) %>%
summarise(pair_count = n()) %>%
arrange(desc(pair_count))
rides_origin_count %>%
top_n(20, origin_count) %>%
ggplot(aes(x = reorder(as.factor(pickup_community_area), origin_count), y = origin_count)) +
geom_col(fill = "steelblue") +
coord_flip() +
labs(title = "Top 20 Community Areas by Ride Origin Count",
x = "Pickup Community Area",
y = "Number of Rides") +
theme_minimal()
rides_dest_count %>%
top_n(20, dest_count) %>%
ggplot(aes(x = reorder(as.factor(dropoff_community_area), dest_count), y = dest_count)) +
geom_col(fill = "darkorange") +
coord_flip() +
labs(title = "Top 20 Community Areas by Ride Destination Count",
x = "Dropoff Community Area",
y = "Number of Rides") +
theme_minimal()
top_pairs <- popular_pairs %>%
ungroup() %>%
arrange(desc(pair_count)) %>%
slice_head(n = 20)
edges <- top_pairs %>%
select(from = pickup_community_area, to = dropoff_community_area, weight = pair_count)
# Convert to character to avoid igraph warnings
edges$from <- as.character(edges$from)
edges$to <- as.character(edges$to)
library(igraph)
library(ggraph)
g <- graph_from_data_frame(edges, directed = TRUE)
# Plot using ggraph
ggraph(g, layout = "fr") +  # Fruchterman-Reingold layout (force-directed)
geom_edge_link(aes(width = weight), alpha = 0.8, colour = "steelblue") +
geom_node_point(size = 5, color = "tomato") +
geom_node_text(aes(label = name), repel = TRUE, size = 3) +
scale_edge_width(range = c(0.5, 3)) +
labs(title = "Popular Ride Flows Between Community Areas",
edge_width = "Number of Rides") +
theme_void()
ggplot(top_pairs, aes(x = reorder(paste(pickup_community_area, dropoff_community_area, sep = "→"), pair_count),
y = pair_count, fill = pair_count)) +
geom_col() +
coord_flip() +
scale_fill_viridis_c(option = "plasma") +
labs(title = "Top 20 Popular Community Area Pairs by Ride Count",
x = "Pickup → Dropoff Community Area",
y = "Number of Rides") +
theme_minimal()
ensureLibrary <- function(pkg) {
if (!requireNamespace(pkg, quietly = TRUE)) {
install.packages(pkg)
}
library(pkg, character.only = TRUE)
}
ensureLibrary("httr")
ensureLibrary("jsonlite")
ensureLibrary("dplyr")
ensureLibrary("tidyr")
ensureLibrary("lubridate")
ensureLibrary("ggplot2")
ensureLibrary("readr")
ensureLibrary("caret")
ensureLibrary("purrr")
files <- list.files("all_data", pattern = "^chicago_taxi_\\d{4}_\\d{2}\\.csv$", full.names = TRUE)
taxi_data <- files %>%
map_dfr(~ read_csv(.x, show_col_types = FALSE))
glimpse(taxi_data)
numeric_columns <- c("trip_start_timestamp",
"trip_end_timestamp",
"trip_seconds",
"trip_miles",
"fare",
"tips",
"tolls",
"extras",
"trip_total",
"pickup_community_area",
"dropoff_community_area")
taxi_data %>% select(all_of(numeric_columns)) %>% summary()
df <- taxi_data %>%
drop_na(trip_seconds, trip_miles, fare) %>%
filter(trip_seconds > 0, trip_miles > 0, fare > 0)
par(mfrow = c(1, 3))
boxplot(df$trip_seconds, main = "Trip Seconds", col = "lightblue")
boxplot(df$trip_miles, main = "Trip Miles", col = "lightgreen")
boxplot(df$fare, main = "Fare", col = "lightcoral")
par(mfrow = c(1, 1))
remove_outliers <- function(x) {
Q1 <- quantile(x, 0.25, na.rm = TRUE)
Q3 <- quantile(x, 0.75, na.rm = TRUE)
IQR_val <- Q3 - Q1
lower <- Q1 - 1.5 * IQR_val
upper <- Q3 + 1.5 * IQR_val
return(x >= lower & x <= upper)
}
df <- df %>%
filter(
remove_outliers(trip_seconds),
remove_outliers(trip_miles),
remove_outliers(fare)
)
par(mfrow = c(1, 3))
boxplot(df$trip_seconds, main = "Trip Seconds", col = "lightblue")
boxplot(df$trip_miles, main = "Trip Miles", col = "lightgreen")
boxplot(df$fare, main = "Fare", col = "lightcoral")
par(mfrow = c(1, 1))
df <- df %>% mutate(
speed_proxy = (trip_miles / 1.60934) / (trip_seconds/60/60)
)
df %>% select(speed_proxy, trip_miles, trip_seconds, fare) %>% summary()
par(mfrow = c(1, 3))
boxplot(df$speed_proxy, main = "Speed_proxy", col = "lightgray")
boxplot(filter(df, trip_miles > 0.5 )$speed_proxy, main = "Speed for miles>0.5", col = "lightgray")
boxplot(filter(df, remove_outliers(speed_proxy))$speed_proxy, main = "Speed cutted", col = "lightgray")
par(mfrow = c(1, 1))
df <- df %>%
filter(remove_outliers(speed_proxy))
nrow(df)
df <- df %>%
mutate(
change_ca_flag = case_when(
is.na(pickup_community_area) ~ "unavailable",
is.na(dropoff_community_area) ~ "unavailable",
pickup_community_area == dropoff_community_area ~ "single-area",
pickup_community_area != dropoff_community_area ~ "changed"
),
change_ca_flag = factor(change_ca_flag)
)
df %>% select(change_ca_flag) %>% table() %>% pie()
df <- df %>%
mutate(
hour = hour(trip_start_timestamp),
day_part = case_when(
hour >= 0 & hour < 6   ~ "night",
hour >= 6 & hour < 12  ~ "morning",
hour >= 12 & hour < 18 ~ "midday",
hour >= 18 & hour <= 23 ~ "evening"
),
day_part = factor(
day_part,
levels = c("night", "morning", "midday", "evening"),
ordered = TRUE
),
weekday = case_when(
wday(trip_start_timestamp, week_start = 1) == 1 ~ "Mon",
wday(trip_start_timestamp, week_start = 1) == 2 ~ "Tue",
wday(trip_start_timestamp, week_start = 1) == 3 ~ "Wed",
wday(trip_start_timestamp, week_start = 1) == 4 ~ "Thu",
wday(trip_start_timestamp, week_start = 1) == 5 ~ "Fri",
wday(trip_start_timestamp, week_start = 1) == 6 ~ "Sat",
wday(trip_start_timestamp, week_start = 1) == 7 ~ "Sun"
),
weekday = factor(
weekday,
levels = c("Mon", "Tue", "Wed", "Thu", "Fri", "Sat", "Sun"),
ordered = TRUE
)
)
#par(mfrow = c(3, 1))
df %>% select(hour) %>% table() %>% barplot()
df %>% select(day_part) %>% table() %>% barplot()
df %>% select(weekday) %>% table() %>% barplot()
#par(mfrow = c(1, 1))
if(interactive()){
# NOTE open in Viewer Pan
summarytools::dfSummary(df) |> summarytools::view()
} else {
summarytools::dfSummary(df) |> print(method = "render")
}
mainEffects <- caret::dummyVars(~weekday, df, sep = ".")
#caret::class2ind(mainEffects)
predict(mainEffects, df["weekday"]) %>% head()
nn_df <- cbind(df,
class2ind(df$weekday),
class2ind(df$change_ca_flag),
class2ind(df$day_part)) %>%
select(fare, trip_seconds,trip_miles, speed_proxy,26:31,33:34,36:38)
nn_df %>% skimr::skim()
