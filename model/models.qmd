---
title: "Model"
author: "Nicolas Pozdena BSc."
format: pdf
editor: visual
---

```{r echo: false}

ensureLibrary <- function(pkg) {
  suppressPackageStartupMessages({
    if (!requireNamespace(pkg, quietly = TRUE)) {
      install.packages(pkg)
    }
    library(pkg, character.only = TRUE)
  })
}

ensureLibrary("httr")
ensureLibrary("jsonlite")
ensureLibrary("dplyr")
ensureLibrary("tidyr")
ensureLibrary("lubridate")
ensureLibrary("ggplot2")
ensureLibrary("readr")
ensureLibrary("caret")
ensureLibrary("purrr")
ensureLibrary("ggplot2")
ensureLibrary("neuralnet")
ensureLibrary("xgboost")
ensureLibrary("randomForest")
ensureLibrary("patchwork")
ensureLibrary("Metrics")

```

```{r echo: false}
load_all_csv <- function(folder_path) {
  
 files <- list.files(path = folder_path, pattern = "\\.csv$", full.names = TRUE)

  if (length(files) == 0) {
    warning("No CSV files found in the folder.")
    return(NULL)
  }

  all_data <- list()
  
  for (f in files) {
    temp <- read.csv(f)
    temp <- temp%>% select(-X, -trip_start_timestamp, -pickup_census_tract, -dropoff_census_tract, -pickup_census_tract_centroid, -dropoff_census_tract_centroid, -type, -dropoff_census_tract.1, -pickup_census_tract.1) %>% mutate(weekday = as.factor(weekday))
    all_data[[f]] <- temp  # use filename as list name (optional but useful)
  }

  return(all_data)
}

evaluate_and_plot_full_model <- function(y, duration_seconds, prediction, model = "Model", dataset = "Dataset") {
  if (length(y) != length(prediction) || length(y) != length(duration_seconds)) {
    stop("All input vectors must have the same length.")
  }

  # Convert inputs
  y <- as.numeric(y)
  prediction <- as.numeric(prediction)
  duration_minutes <- duration_seconds / 60

  # --- Metrics ---
  valid_idx <- which(!is.na(y) & !is.na(prediction) & !is.na(duration_minutes) & y != 0)
  y_valid <- y[valid_idx]
  prediction_valid <- prediction[valid_idx]
  duration_valid <- duration_minutes[valid_idx]

  rmse_val <- tryCatch(rmse(y_valid, prediction_valid), error = function(e) NA)
  mae_val <- tryCatch(mae(y_valid, prediction_valid), error = function(e) NA)
  r2_val <- tryCatch(1 - sum((y_valid - prediction_valid)^2) / sum((y_valid - mean(y_valid))^2), error = function(e) NA)

  
  
  
  
  
  
  
   duration_n_10min <- max(duration_valid %/% 10, 1) # how many 10-minute intervals in each trip
  rmse_10min <- round(sqrt(mean( ( 
    (y_valid - prediction_valid)/duration_n_10min
    )^2 , na.rm = TRUE)),2)
  

  ae_percent <- (abs(y_valid - prediction_valid) / y_valid) * 100 - 1
  mean_ae_percent <- round(mean(ae_percent, na.rm = TRUE),2)
  
  
 

  is_ok <- (rmse_10min < 2) & (mean_ae_percent < 0.05)

  # --- Plots ---

  # 1. Prediction vs Actual
  p_pred <- ggplot(data.frame(y = y_valid, prediction = prediction_valid), aes(x = y, y = prediction)) +
    geom_point(color = "steelblue", alpha = 0.6) +
    geom_abline(intercept = 0, slope = 1, color = "red", linetype = "dashed") +
    labs(
      title = paste(model, "Predictions"),
      subtitle = paste0("(N = ", length(y_valid), ")"),
      x = "Actual",
      y = "Predicted"
    ) +
    theme_minimal()

  # 2. Metric bar chart
  metric_df <- data.frame(
    Metric = c("RMSE", "MAE", "R²"),
    Value = c(rmse_val, mae_val, r2_val)
  )

  p_metrics <- ggplot(metric_df, aes(x = Metric, y = Value, fill = Metric)) +
    geom_col(width = 0.6, show.legend = FALSE) +
    geom_text(aes(label = round(Value, 2)), vjust = -0.5, size = 4) +
    scale_y_continuous(expand = expansion(mult = c(0, 0.4))) +
    labs(
      title = "Model Evaluation Metrics",
      y = NULL, x = NULL
    ) +
    theme_minimal()

  # 3. Summary: RMSE 10min vs %AE
  summary_df <- data.frame(
    RMSE_10min = rmse_10min,
    Mean_AE_percent = mean_ae_percent,
    Status = ifelse(is_ok, "OK", "Not OK")
  )

  p_summary <- ggplot(summary_df, aes(x = RMSE_10min, y = Mean_AE_percent)) +
    geom_point(aes(color = Status), size = 5) +
    geom_vline(xintercept = 2, linetype = "dashed", color = "black") +
    geom_hline(yintercept = 0.05, linetype = "dashed", color = "black") +
    scale_color_manual(values = c("OK" = "green", "Not OK" = "red")) +
    labs(
      title = "Evaluation: Scaled RMSE vs % Error",
      x = "RMSE (scaled to 10 min)",
      y = "Mean Absolute Error (%)"
    ) +
    theme_minimal()

  # 4. Individual error scatter
  individual_df <- data.frame(
    AbsoluteError_10min = abs(y_valid - prediction_valid) * (10 / duration_valid),
    PercentError = ae_percent
  )
  
  thresholds_df <- data.frame(
  Metric = c("RMSE_10min", "Mean AE %"),
  Value = c(rmse_10min, mean_ae_percent),
  Threshold = c(2, 0.05)
)

p_thresholds <- ggplot(thresholds_df, aes(x = Metric, y = Value, fill = Metric)) +
  geom_col(width = 0.5, show.legend = FALSE) +
  geom_hline(aes(yintercept = Threshold), linetype = "dashed", color = "red") +
  geom_text(aes(label = round(Value, 2)), vjust = -0.5, size = 4) +
  scale_y_continuous(expand = expansion(mult = c(0, 0.2))) +
  labs(
    title = "Scaled Error Metrics vs Thresholds",
    y = "Value", x = NULL
  ) +
  theme_minimal()

  p_individual <- ggplot(individual_df, aes(x = AbsoluteError_10min, y = duration_valid)) +
    geom_point(alpha = 0.6, color = "blue") +
    geom_hline(yintercept = 0.05, linetype = "dashed", color = "black") +
    labs(
      title = "Individual Errors",
      x = "Absolute Error (scaled to 10 min)",
      y = "duration in minutes"
    ) +
    theme_minimal()
  
  
  # RMSE_10min Bar Plot
p_rmse10 <- ggplot(data.frame(Value = rmse_10min), aes(x = "RMSE (10min)", y = Value)) +
  geom_col(fill = ifelse(rmse_10min <= 2, "green", "red"), width = 0.5) +
  geom_hline(yintercept = 2, linetype = "dashed", color = "black") +
  geom_text(aes(label = round(Value, 2)), vjust = -0.5, size = 4) +
  scale_y_continuous(expand = expansion(mult = c(0, 0.2))) +
  labs(
    title = "RMSE scaled to 10 minutes",
    x = NULL,
    y = NULL
  ) +
  theme_minimal() +
  ylim(c(0,5))

# Mean AE % Bar Plot
p_ae_percent <- ggplot(data.frame(Value = mean_ae_percent), aes(x = "Mean AE %", y = Value)) +
  geom_col(fill = ifelse(mean_ae_percent <= 5, "green", "red"), width = 0.5) +
  geom_hline(yintercept = 5, linetype = "dashed", color = "black") +
  geom_text(aes(label = round(Value, 3)), vjust = -0.5, size = 4) +
  scale_y_continuous(expand = expansion(mult = c(0, 0.2))) +
  labs(
    title = "Mean Absolute Error %",
    x = NULL,
    y = NULL
  ) +
  theme_minimal() + 
  ylim(c(0,100))

  # --- Combine plots ---
  combined_plot <- (p_pred | p_metrics) / ((p_rmse10 | p_ae_percent) | p_individual)
  return(combined_plot)
}
```

# Modelling

## loading dataset


```{r}
df <- load_all_csv("../all_data")

```

```{r}
reducedDf <- df %>% 
  select(
    trip_start_timestamp, 
    pickup_centroid_latitude, 
    pickup_centroid_longitude, 
    dropoff_centroid_latitude, 
    dropoff_centroid_longitude, 
    trip_seconds, 
    trip_miles, 
    fare) %>%
  filter(
    !is.na(trip_start_timestamp) &  
    !is.na(pickup_centroid_latitude) &  
    !is.na(pickup_centroid_longitude) &  
    !is.na(dropoff_centroid_latitude) &  
    !is.na(dropoff_centroid_longitude) & 
    trip_seconds>0 & 
    trip_miles > 0 & 
    fare > 0)

rm(df)

```

## splits

```{r}
set.seed(111)

size = nrow(reducedDf)
wholeData <- sample(1:size, 0.01 * size)
mD <- reducedDf[wholeData, ]


workOnData <- function(modelData){
  
  modelData$weekday <- as.factor(weekdays(modelData$trip_start_timestamp))
  modelData$day <- as.POSIXlt(modelData$trip_start_timestamp)$mday
  modelData$month <- as.POSIXlt(modelData$trip_start_timestamp)$mon + 1
  modelData$year <- as.POSIXlt(modelData$trip_start_timestamp)$year + 1900
  
  ts_lt <- as.POSIXlt(modelData$trip_start_timestamp)
  
  # Extract hours, minutes, seconds
  hour <- ts_lt$hour
  minute <- ts_lt$min
  second <- ts_lt$sec
  
  
  time_decimal <- hour + minute / 60 + second / 3600
  
  
  modelData$time <- time_decimal
  
  
  modelData <- modelData %>% select(-trip_start_timestamp)
  
  modelData %>% head()
  
  rm(hour)
  rm(minute)
  rm(second)
  rm(ts_lt)
  rm(time_decimal)
  
  return(modelData)
}

mD <- workOnData(mD) 

```

```{r}

train_index <- sample(1:nrow(mD), 0.8 * nrow(mD))
train <- mD[train_index, ]
test <- mD[-train_index, ]

```

```{r}
form <- fare ~ .
```

### Neural Net

```{r}


train_matrix <- model.matrix(form, data = train)[, -1]
test_matrix  <- model.matrix(form, data = test)[, -1]


train_data_nn <- data.frame(fare = train$fare, train_matrix)
test_data_nn  <- data.frame(fare = test$fare, test_matrix)


nn_formula <- as.formula(paste("fare ~", paste(colnames(train_matrix), collapse = " + ")))


model_nn <- neuralnet(nn_formula, data = train_data_nn, hidden = c(2, 3),linear.output = FALSE)
pred_nn <- compute(model_nn, test_matrix)$net.result

showPredictions(pred_nn, test$fare, "Neural Net")
```

### GLM

```{r}
model_glm <- glm(form, data=train)
pred_glm <- predict(model_glm, newdata=test)

showPredictions(pred_glm, test$fare, "GLM")
```

### XGBoost

```{r}
x_train <- model.matrix(form, data = train)[, -1]
x_test  <- model.matrix(form, data = test)[, -1]
y_train <- train$fare
y_test  <- test$fare

model_xgb <- xgboost(data = x_train,label = y_train,nrounds = 50, objective = "reg:squarederror", verbose = 0)
pred_xgb <- predict(model_xgb, newdata = x_test)

showPredictions(pred_xgb, y_test, "XGBoost")

```

### Random Forest

```{r}
model_rf <- randomForest(form, data=train)
pred_rf <- predict(model_rf, newdata=test)

showPredictions(pred_rf, test$fare, "Random Forrest")
```

### LM

```{r}
model_lm <- lm(form, data=train)
pred_lm <- predict(model_lm, newdata=test)

showPredictions(pred_lm, test$fare, "Linear Model")

```

## percentage test

```{r}
set.seed(123)
target_col <- "fare"
form <- as.formula(paste(target_col, "~ ."))
percentages <- c(0.001, 0.002, 0.003, 0.004, 0.005)


results <- data.frame()

# Loop through each percentage
for (p in percentages) {
  print(paste("Running", p*100, "%"))
  
  n_rows <- ceiling(nrow(reducedDf) * p)
  df_sample <- reducedDf[sample(nrow(reducedDf), n_rows), ]
  
  df_sample <- workOnData(df_sample)

  train_idx <- sample(1:nrow(df_sample), size = 0.8 * nrow(df_sample))
  train <- df_sample[train_idx, ]
  test  <- df_sample[-train_idx, ]

  y_test <- test[[target_col]]
  
  # ---- MODELS ----

  model_list <- list()

  # 1. LM
  start_time <- Sys.time()
  model <- lm(form, data = train)
  elapsed <- Sys.time() - start_time
  preds <- predict(model, newdata = test)
  model_list[["LM"]] <- list(time = elapsed, pred = preds)

  # 2. GLM
  start_time <- Sys.time()
  model <- glm(form, data = train)
  elapsed <- Sys.time() - start_time
  preds <- predict(model, newdata = test)
  model_list[["GLM"]] <- list(time = elapsed, pred = preds)

  # 3. Random Forest
  start_time <- Sys.time()
  model <- randomForest(form, data = train)
  elapsed <- Sys.time() - start_time
  preds <- predict(model, newdata = test)
  model_list[["RF"]] <- list(time = elapsed, pred = preds)

  # 4. XGBoost
  x_train <- model.matrix(form, data = train)[, -1]
  x_test  <- model.matrix(form, data = test)[, -1]
  y_train <- train[[target_col]]
  
  start_time <- Sys.time()
  model <- xgboost(data = x_train, label = y_train, nrounds = 20, objective = "reg:squarederror", verbose = 0)
  elapsed <- Sys.time() - start_time
  preds <- predict(model, newdata = x_test)
  model_list[["XGB"]] <- list(time = elapsed, pred = preds)


  # ---- Collect results ----
  for (model_name in names(model_list)) {
    entry <- model_list[[model_name]]
    preds <- entry$pred
    elapsed <- entry$time
    
    rmse_val <- rmse(y_test, preds)
    mae_val  <- mae(y_test, preds)
    r2_val   <- 1 - sum((y_test - preds)^2) / sum((y_test - mean(y_test))^2)

    results <- rbind(results, data.frame(
      percentage = p,
      rows = n_rows,
      model = model_name,
      time = as.numeric(elapsed, units = "secs"),
      rmse = rmse_val,
      mae = mae_val,
      r2 = r2_val
    ))
  }
}

# Show results
print(results)
```

```{r}

results %>%
  ggplot(aes(x = as.factor(rows), y = rmse, color = model, size=time)) +
  geom_point() +
  labs(
    title = "RMSE by Model and Data Percentage",
    x = "ROWS",
    y = "RMSE",
    fill = "Model"
  ) +
  theme_minimal()

```

```{r}

metric_deltas_scaled <- results %>% filter(rows != 20827) %>%
  arrange(model, rows) %>%
  group_by(model) %>%
  mutate(
    delta_rows = rows - lag(rows),
    delta_rmse = rmse - lag(rmse),
    delta_mae  = mae  - lag(mae),
    delta_r2   = r2   - lag(r2),
    delta_time = time - lag(time)
  ) %>%
  filter(!is.na(delta_rows) & delta_rows > 0) %>%
  summarise(
    rmse_per_10k = mean(delta_rmse / delta_rows * 10000, na.rm = TRUE),
    mae_per_10k  = mean(delta_mae / delta_rows * 10000, na.rm = TRUE),
    r2_per_10k   = mean(delta_r2  / delta_rows * 10000, na.rm = TRUE),
    time_per_10k = mean(delta_time/ delta_rows * 10000, na.rm = TRUE)
  )
metric_deltas_scaled
```




```{r}
evaluate_model <- function(y, duration_seconds, prediction) {
  if (length(y) != length(prediction) || length(y) != length(duration_seconds)) {
    stop("All input vectors must have the same length.")
  }

  # Convert duration from seconds to minutes
  duration_minutes <- duration_seconds / 60
  
  # Metric 1: RMSE scaled to 10 minutes
  # Compute squared errors
  squared_errors <- (y - prediction)^2
  
  # Scale errors per 10 minutes
  scaling_factors <- 10 / duration_minutes
  rmse_10min <- sqrt(mean(squared_errors * scaling_factors^2, na.rm = TRUE))
  
  # Metric 2: Mean Absolute Error as percentage of true value
  ae_percent <- abs(y - prediction) / y
  mean_ae_percent <- mean(ae_percent, na.rm = TRUE)
  
  # Return results
  list(
    RMSE_10min = rmse_10min,
    RMSE_10min_OK = rmse_10min < 2,
    Mean_AE_percent = mean_ae_percent,
    Mean_AE_percent_OK = mean_ae_percent < 0.05
  )
}

```




```{r}
loadDataSets <- function(folderPath){
  files <- list.files(folderPath, full.names = TRUE)
  ds <- list()  # Initialize as list to hold data frames
  for (f in files) {
    print(f)
    data <- read.csv(f)
    ds[[f]] <- data  # Store each data frame in list, named by file path
  }
  return(ds)
}

```



```{r}

datas <- loadDataSets("../all_data/datasets")

for (name in names(datas)) {
  d <- datas[[name]]
  d <- d %>% select(-trip_start_timestamp, -weekday, -pickup_census_tract_centroid, -dropoff_census_tract_centroid)
  # Split into train/test
  set.seed(42)
  train_index <- sample(1:nrow(d), 0.8 * nrow(d))
  train <- d[train_index, ]
  test <- d[-train_index, ] 
  
  # Train linear model
  linearModel <- lm(fare ~ ., data = train)
  print("linear model trained")
  
  
  # Predict on test set
  predictions <- predict(linearModel, newdata = test%>%select(-fare))
  print("predictions")
  
  # Evaluate metrics
  results <- evaluate_model(y = test$fare,
                            duration_seconds = test$trip_seconds,  # adjust column name if needed
                            prediction = predictions)
  
  cat(sprintf("Results for %s:\n", name))
  print(results)
  cat("\n")
}
```

```{r}

remove_outliers_z <- function(df, feature1, feature2, threshold = 3) {
  z1 <- abs(scale(df[[feature1]]))
  z2 <- abs(scale(df[[feature2]]))
  
  df_clean <- df[(z1 < threshold) & (z2 < threshold), ]
  return(df_clean)
}

```


```{r}
df <- load_all_csv("../all_data/datasets")
form <- fare ~ .
percentage <- 0.8
```


```{r}
models <- list(
   "XGBOOST" = xgboost,
  "GLM" = glm,
  "LM" = lm
)
counter = 0

for (ds in rev(names(df))) {
    dataSet <- df[[ds]] %>% filter(trip_seconds > 60)
    dataSet$weekday <- as.numeric(factor(dataSet$weekday))
    dataSet$fareSeconds <- dataSet$fare/dataSet$trip_seconds
    dataSet <- remove_outliers_z(dataSet, "fare", "fareSeconds", 1.5)
    dataSet <- remove_outliers_z(dataSet, "trip_miles", "trip_seconds", 1.5)
    dataSet <- dataSet %>% select(-fareSeconds)
    train_index <- sample(1:nrow(dataSet), percentage * nrow(dataSet))
    train <- dataSet[train_index, ] %>% drop_na()
    test <- dataSet[-train_index, ] %>% drop_na()
    
    test_durations <- test$trip_seconds
    
    
    scale_params <- preProcess(train[, -which(names(train) == "fare")], method = c("center", "scale"))
    train_scaled <- predict(scale_params, train)
    test_scaled <- predict(scale_params, test)
    
    train_scaled$fare <- train$fare
    test_scaled$fare <- test$fare
    train <- train_scaled
    test <- test_scaled
    
     # Extract target and clean test set
    y <- test$fare
  
  for (m in names(models)) {
    print(paste0("Working on ", m , " with ", ds))
    
    model_obj <- NULL
    pred <- NULL
    
     tryCatch({
      if (m == "XGBOOST") {
          train_clean <- train 
          test_clean <- test
        
          xform <- fare ~ . - 1  # consistent formula without intercept

          train_matrix <- model.matrix(xform, data = train_clean)
          test_matrix <- model.matrix(xform, data = test_clean)
        
          # Prepare labels and durations
          train_labels <- train_clean$fare
          test_labels <- test_clean$fare
          
        
          # DMatrix conversion
          dtrain <- xgb.DMatrix(data = train_matrix, label = train_labels)
          dtest <- xgb.DMatrix(data = test_matrix)
        
          # Train
          params <- list(objective = "reg:squarederror", eta = 0.1, max_depth = 6)
          model_obj <- xgboost(data = dtrain, params = params, nrounds = 100, verbose = 0)
        
          # Predict
          pred <- predict(model_obj, dtest)
        
          # Evaluate
          print(evaluate_and_plot_full_model(
            y = test_labels,
            duration_seconds = test_durations,
            prediction = pred,
            model = m,
            dataset = ds
          ))
          
          save_path <- paste0("fare_xgb_",counter,".model")
          xgb.save(model_obj, save_path)
          counter <- counter +1
      } else {
        model_func <- models[[m]]
        model_obj <- model_func(form, data = train, na.action = na.omit)
        pred <- predict(model_obj, newdata = test %>% select(-fare))
        print(evaluate_and_plot_full_model(y, test$trip_seconds, pred, model = m, dataset = ds))
      }
    
    
    # Plot evaluation
    
     }, error = function(e) {
      cat(paste0("❌ Error with model ", m, " on dataset ", ds, ": ", e$message, "\n"))
    })
  }

}
```

```{r}
models <- list(             # handled in its own block      # random-forest
  "RF" = NULL        # feed-forward neural net
)

# ----------------------------------------------------------------------------- 

  

    dataSet <- df[["../all_data/datasets/dsSmall.csv"]] %>% filter(trip_seconds > 60)
    dataSet <- na.omit(dataSet)
    dataSet$weekday <- as.numeric(factor(dataSet$weekday))
    dataSet$fareSeconds <- dataSet$fare/dataSet$trip_seconds
    dataSet <- remove_outliers_z(dataSet, "fare", "fareSeconds", 1.5)
    dataSet <- remove_outliers_z(dataSet, "trip_miles", "trip_seconds", 1.5)
    dataSet <- dataSet %>% select(-fareSeconds)
    train_index <- sample(1:nrow(dataSet), 0.3 * nrow(dataSet))
    train <- dataSet[train_index, ]
    test <- dataSet[-train_index, ]
    
    scale_params <- preProcess(train[, -which(names(train) == "fare")], method = c("center", "scale"))
    train <- predict(scale_params, train)
    test <- predict(scale_params, test)
    
     # Extract target and clean test set
    y <- test$fare
  
  for (m in names(models)) {
    print(sprintf("▶️  Working on %s with  …", m ))
    
    tryCatch({
      if (m == "RF") {
        # ----- Random-Forest --------------------------------------------------
        model_obj <- randomForest(as.formula("fare ~ ."), data = train, na.action = na.omit)
        pred <- predict(model_obj, newdata = test, type = "response")
        
      } else if (m == "NEURALNET") {
        # ----- Neural-net -----------------------------------------------------
        # neuralnet needs purely numeric matrix input
        nn_train <- model.matrix(form, data = train)[, -1]  # drop intercept
        nn_test  <- model.matrix(form, data = test)[, -1]
        
        nn_df <- cbind(fare = train$fare, as.data.frame(nn_train))
        nn_formula <- as.formula(paste("fare ~", 
                                       paste(colnames(nn_train), collapse = " + ")))
        
        model_obj <- neuralnet("fare ~ .", data = nn_df, hidden = c(2),
                               linear.output = TRUE, stepmax = 1e6)
        pred_raw <- compute(model_obj, nn_test)$net.result
        pred <- as.numeric(pred_raw)
        
      } else {
        
      }
      
      # ----- common evaluation ----------------------------------------------
      print(evaluate_and_plot_full_model(
        y               = y,
        duration_seconds = test$trip_seconds,
        prediction      = pred,
        model           = m,
        dataset         = "../all_data/datasets/dsSmall.csv"
      ))
      
    }, error = function(e) {
      message(sprintf("❌ Error with model %s on dataset: %s", m, e$message))
    })
  }


```

